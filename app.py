import os
import sqlite3
import tempfile
import pandas as pd
from bs4 import BeautifulSoup
import requests
from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import gradio as gr
from langchain_community.document_loaders import PyPDFLoader

# Configura√ß√µes
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)

# Vari√°veis globais para armazenamento em mem√≥ria
pdf_documents = []
vectordb_pdf = None
qa_chain_pdf = None

# Mapeamento de temas para links sobre a prova
temas_para_links = {
    "estruturas de prova": "https://www.florence.edu.br/blog/como-e-dividida-a-prova-do-enem/",
    "linguagens, c√≥digos e suas tecnologias": "https://www.todamateria.com.br/linguagens-codigos-e-suas-tecnologias/",
    "Ci√™ncias Humanas e suas Tecnologias": "https://www.todamateria.com.br/ciencias-humanas-e-suas-tecnologias/",
    "Ci√™ncias da Natureza e suas Tecnologias": "https://www.todamateria.com.br/ciencias-da-natureza-e-suas-tecnologias/",
    "Matem√°tica e suas Tecnologias": "https://fia.com.br/blog/matematica-e-suas-tecnologias/",
    "reda√ß√£o": "https://vestibular.brasilescola.uol.com.br/enem/saiba-tudo-sobre-a-redacao-do-enem.htm"
}

# Inicializa o LLM e a mem√≥ria
llm = ChatOpenAI(
    model="deepseek/deepseek-r1:free", 
    temperature=0.4,
    openai_api_key=os.environ.get("OPENROUTER_API_KEY"),
    openai_api_base="https://openrouter.ai/api/v1"
)
memoria = ConversationBufferMemory(memory_key="chat_history", return_messages=True, output_key="answer")

# Cria banco de dados SQLite em mem√≥ria
conn = sqlite3.connect(":memory:")
cursor = conn.cursor()
cursor.execute('''
CREATE TABLE IF NOT EXISTS conversas (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    aluno TEXT,
    pergunta TEXT,
    resposta TEXT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
)
''')
conn.commit()

# Fun√ß√µes auxiliares
def processar_pdfs(files):
    global pdf_documents, vectordb_pdf, qa_chain_pdf

    pdf_documents = []
    if not files:
        return "‚ö†Ô∏è Nenhum arquivo foi enviado."

    for file in files:
        try:
            # Se for NamedString
            if isinstance(file, gr.FileData) or hasattr(file, "path"):
                tmp_path = file.path
                file_name = getattr(file, 'name', 'Arquivo desconhecido')
            elif isinstance(file, str):
                tmp_path = file  # Assume que o 'file' √© um caminho direto
                file_name = os.path.basename(file)
            else:
                return f"‚ùå Formato de arquivo n√£o suportado: {str(type(file))}"

            if not tmp_path or not os.path.exists(tmp_path):
                return f"‚ùå Arquivo {file_name} n√£o encontrado no caminho {tmp_path}"

            # Processa o arquivo PDF
            loader = PyPDFLoader(tmp_path)
            docs = loader.load_and_split(text_splitter)
            pdf_documents.extend(docs)

        except Exception as e:
            return f"‚ùå Erro ao processar {file_name if 'file_name' in locals() else 'PDF'}: {str(e)}"

    if pdf_documents:
        try:
            vectordb_pdf = FAISS.from_documents(pdf_documents, embeddings)
            qa_chain_pdf = ConversationalRetrievalChain.from_llm(
                llm=llm,
                retriever=vectordb_pdf.as_retriever(),
                memory=memoria,
                return_source_documents=True,
                output_key="answer"
            )
            return f"‚úÖ {len(files)} PDF(s) processado(s) - {len(pdf_documents)} trechos!"
        except Exception as e:
            return f"‚ùå Erro ao criar vetores: {str(e)}"
    return "‚ö†Ô∏è Nenhum dado v√°lido para processar."

def responder(pergunta, nome):
    try:
        # Primeiro tenta encontrar na documenta√ß√£o web
        link = identificar_tema(pergunta)
        if link:
            loader = WebBaseLoader(link)
            docs = loader.load()
            if docs:
                documents = text_splitter.split_documents(docs)
                vectordb = FAISS.from_documents(documents, embeddings)
                retriever = vectordb.as_retriever()
                resultado = ConversationalRetrievalChain.from_llm(
                    llm=llm,
                    retriever=retriever,
                    memory=memoria,
                    return_source_documents=True,
                    output_key="answer"
                ).invoke({"question": pergunta})
                resposta = resultado["answer"].content if hasattr(resultado["answer"], "content") else str(resultado["answer"])
                salvar_conversa(nome, pergunta, resposta)
                return resposta
        
        # Se n√£o encontrou na web, tenta nos PDFs locais
        if pdf_documents:
            resultado = qa_chain_pdf.invoke({"question": pergunta})
            resposta = resultado["answer"]
            salvar_conversa(nome, pergunta, resposta)
            return resposta
        
        # Fallback para o LLM puro
        resposta = llm.invoke(pergunta).content
        salvar_conversa(nome, pergunta, resposta)
        return resposta

    except Exception as e:
        return f"‚ùå Erro ao processar sua pergunta: {str(e)}"

def resetar_memoria():
    memoria.clear()
    return "‚úÖ Mem√≥ria da conversa foi resetada!"

def exportar_conversas():
    df = pd.read_sql_query("SELECT * FROM conversas ORDER BY timestamp DESC", conn)
    
    # Cria arquivos tempor√°rios
    with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_csv:
        df.to_csv(tmp_csv.name, index=False)
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp_xlsx:
        df.to_excel(tmp_xlsx.name, index=False, engine="openpyxl")
    
    return [tmp_csv.name, tmp_xlsx.name]

# Interface Gradio
with gr.Blocks(title="Tutor de ENEM - Hugging Face") as app:
    gr.Markdown("## ü§ñ Tutor de ENEM - Busca em M√∫ltiplos PDFs")
    
    with gr.Tab("üìö Upload de PDFs"):
        file_input = gr.File(label="Selecione os PDFs", file_count="multiple", file_types=[".pdf"])
        upload_button = gr.Button("Processar PDFs")
        upload_status = gr.Textbox(label="Status")
        upload_button.click(processar_pdfs, inputs=file_input, outputs=upload_status)
    
    with gr.Tab("üí¨ Conversar"):
        with gr.Row():
            nome = gr.Textbox(label="Seu nome (opcional)", placeholder="Ex: Jo√£o")
            pergunta = gr.Textbox(label="Sua d√∫vida sobre o ENEM", placeholder="Ex: Como se preparar para o ENEM?")
        resposta = gr.Markdown(value="‚ÑπÔ∏è Aguardando sua pergunta...")
        
        with gr.Row():
            botao_enviar = gr.Button("Enviar", variant="primary")
            botao_resetar = gr.Button("üîÅ Resetar Mem√≥ria")
            botao_exportar = gr.Button("üì§ Exportar Hist√≥rico")

        botao_enviar.click(fn=responder, inputs=[pergunta, nome], outputs=resposta)
        botao_resetar.click(fn=resetar_memoria, outputs=resposta)
        
        export_files = gr.Files(label="Arquivos exportados")
        botao_exportar.click(fn=exportar_conversas, outputs=export_files)

app.launch()